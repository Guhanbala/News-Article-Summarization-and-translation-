{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b0b565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (8.1.7)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: jupyter in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: notebook in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter) (7.4.5)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter) (6.30.1)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter) (4.4.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipykernel->jupyter) (1.8.16)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipykernel->jupyter) (5.8.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipykernel->jupyter) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipykernel->jupyter) (27.0.2)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from ipykernel->jupyter) (6.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-client>=8.0.0->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.4.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (311)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab->jupyter) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab->jupyter) (78.1.1)\n",
      "Requirement already satisfied: tomli>=1.2.2 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab->jupyter) (2.2.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.22.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.25.1)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab->jupyter) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.27.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.1.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from nbconvert->jupyter) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from nbconvert->jupyter) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.21.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20250822)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\gowth\\.conda\\envs\\bart_env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353397f0",
   "metadata": {},
   "source": [
    "# Install compatible versions to fix import errors\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "print(\"Installing compatible package versions...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "try:\n",
    "    # Install NumPy first (compatible version)\n",
    "    print(\"1. Installing NumPy < 2.0...\")\n",
    "    install_package(\"numpy<2.0\")\n",
    "    \n",
    "    # Install PyTorch with CUDA support\n",
    "    print(\"2. Installing PyTorch 2.2.0 with CUDA 12.1...\")\n",
    "    install_package(\"torch==2.2.0+cu121 --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    \n",
    "    # Install compatible torchvision\n",
    "    print(\"3. Installing compatible torchvision...\")\n",
    "    install_package(\"torchvision==0.17.0+cu121 --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    \n",
    "    # Install transformers and other packages\n",
    "    print(\"4. Installing transformers and other packages...\")\n",
    "    install_package(\"transformers==4.30.0\")  # Older stable version\n",
    "    install_package(\"datasets\")\n",
    "    install_package(\"tqdm\")\n",
    "    install_package(\"ipywidgets\")\n",
    "    \n",
    "    print(\"✅ All packages installed successfully!\")\n",
    "    print(\"⚠️  IMPORTANT: Please restart the kernel after installation!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Installation failed: {e}\")\n",
    "    print(\"Please try running these commands manually:\")\n",
    "    print(\"pip install 'numpy<2.0'\")\n",
    "    print(\"pip install 'torch==2.2.0+cu121' --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    print(\"pip install 'torchvision==0.17.0+cu121' --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    print(\"pip install 'transformers==4.30.0'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESTART KERNEL AFTER INSTALLATION COMPLETES!\")Embeddings and GRU Architecture\n",
    "This notebook implements a sequence-to-sequence model for text summarization using BERT embeddings with encoder-decoder GRU architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424bb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a506cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model loaded: bert-base-uncased\n",
      "BERT embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer and model for embeddings\n",
    "\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "# Freeze BERT parameters to use as fixed embeddings\n",
    "for param in bert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(f\"BERT model loaded: {bert_model_name}\")\n",
    "print(f\"BERT embedding dimension: {bert_model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7455e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Downloading CNN/DailyMail dataset...**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 28711 samples out of 287113 total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset: 100%|██████████| 28711/28711 [00:02<00:00, 13193.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load CNN/DailyMail dataset (use subset for faster training)\n",
    "display(Markdown(\"**Downloading CNN/DailyMail dataset...**\"))\n",
    "dataset = load_dataset('abisee/cnn_dailymail', '3.0.0')\n",
    "\n",
    "train_data = dataset['train']\n",
    "# Use only 1/10th of the data for faster training\n",
    "subset_size = len(train_data) // 10\n",
    "train_data = train_data.select(range(subset_size))\n",
    "print(f\"Using {subset_size} samples out of {len(dataset['train'])} total.\")\n",
    "\n",
    "def preprocess(sample):\n",
    "    article = sample['article']\n",
    "    summary = sample['highlights']\n",
    "    return article, summary\n",
    "\n",
    "articles = []\n",
    "summaries = []\n",
    "for i in tqdm(range(len(train_data)), desc='Preprocessing dataset'):\n",
    "    sample = train_data[i]\n",
    "    a, s = preprocess(sample)\n",
    "    articles.append(a)\n",
    "    summaries.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c475c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing articles...\n",
      "Tokenizing summaries...\n",
      "Article tensor shape: torch.Size([28711, 512])\n",
      "Summary tensor shape: torch.Size([28711, 128])\n",
      "BERT vocabulary size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Tokenization using BERT tokenizer\n",
    "def tokenize_with_bert(texts, max_length=512):\n",
    "    \"\"\"Tokenize texts using BERT tokenizer and return input_ids\"\"\"\n",
    "    tokenized = bert_tokenizer(\n",
    "        texts,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return tokenized['input_ids'], tokenized['attention_mask']\n",
    "\n",
    "# Tokenize articles and summaries\n",
    "max_article_len = 512\n",
    "max_summary_len = 128\n",
    "\n",
    "print(\"Tokenizing articles...\")\n",
    "article_ids, article_masks = tokenize_with_bert(articles, max_article_len)\n",
    "print(\"Tokenizing summaries...\")\n",
    "summary_ids, summary_masks = tokenize_with_bert(summaries, max_summary_len)\n",
    "\n",
    "print(f\"Article tensor shape: {article_ids.shape}\")\n",
    "print(f\"Summary tensor shape: {summary_ids.shape}\")\n",
    "\n",
    "# Vocabulary size from BERT tokenizer\n",
    "vocab_size = bert_tokenizer.vocab_size\n",
    "print(f\"BERT vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b3466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 28711 samples\n",
      "DataLoader created with batch size 8\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Dataset with BERT embeddings\n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, article_ids, article_masks, summary_ids, summary_masks):\n",
    "        self.article_ids = article_ids\n",
    "        self.article_masks = article_masks\n",
    "        self.summary_ids = summary_ids\n",
    "        self.summary_masks = summary_masks\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.article_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.article_ids[idx], \n",
    "            self.article_masks[idx],\n",
    "            self.summary_ids[idx], \n",
    "            self.summary_masks[idx]\n",
    "        )\n",
    "\n",
    "dataset = SummarizationDataset(article_ids, article_masks, summary_ids, summary_masks)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)  # Reduced batch size for memory\n",
    "print(f\"Dataset created with {len(dataset)} samples\")\n",
    "print(f\"DataLoader created with batch size 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "073e0fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialized with BERT embeddings\n",
      "Decoder initialized with BERT embeddings\n",
      "Hidden size: 256\n"
     ]
    }
   ],
   "source": [
    "# Encoder-Decoder Model with BERT Embeddings\n",
    "class BERTEncoder(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.bert_hidden_size = bert_model.config.hidden_size  # 768 for bert-base\n",
    "        self.rnn = nn.GRU(self.bert_hidden_size, hidden_size, \n",
    "                         num_layers=num_layers, bidirectional=True, batch_first=True)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERT embeddings\n",
    "        with torch.no_grad():  # BERT parameters are frozen\n",
    "            bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            embeddings = bert_outputs.last_hidden_state  # [batch_size, seq_len, 768]\n",
    "        \n",
    "        # Pass through GRU\n",
    "        outputs, hidden = self.rnn(embeddings)\n",
    "        # Concatenate forward and backward hidden states\n",
    "        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1).unsqueeze(0)\n",
    "        return outputs, hidden\n",
    "\n",
    "class BERTDecoder(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_size, vocab_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.bert_hidden_size = bert_model.config.hidden_size\n",
    "        self.rnn = nn.GRU(self.bert_hidden_size, hidden_size*2, \n",
    "                         num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, vocab_size)\n",
    "        \n",
    "    def forward(self, input_ids, hidden, attention_mask=None):\n",
    "        # Get BERT embeddings\n",
    "        with torch.no_grad():  # BERT parameters are frozen\n",
    "            bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            embeddings = bert_outputs.last_hidden_state\n",
    "        \n",
    "        # Pass through GRU\n",
    "        outputs, hidden = self.rnn(embeddings, hidden)\n",
    "        logits = self.fc(outputs)\n",
    "        return logits, hidden\n",
    "\n",
    "# Initialize models\n",
    "hidden_size = 256\n",
    "encoder = BERTEncoder(bert_model, hidden_size)\n",
    "decoder = BERTDecoder(bert_model, hidden_size, vocab_size)\n",
    "\n",
    "print(f\"Encoder initialized with BERT embeddings\")\n",
    "print(f\"Decoder initialized with BERT embeddings\")\n",
    "print(f\"Hidden size: {hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26368815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA device count: 1\n",
      "Current CUDA device: 0\n",
      "CUDA device name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Models moved to device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3589/3589 [26:05<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 3.4079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3589/3589 [26:24<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 1.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  74%|███████▍  | 2664/3589 [19:25<06:46,  2.27it/s]"
     ]
    }
   ],
   "source": [
    "# Training Loop with BERT embeddings\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Move models to device\n",
    "bert_model.to(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "print(f\"Models moved to device: {device}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=bert_tokenizer.pad_token_id)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    for article_ids, article_masks, summary_ids, summary_masks in tqdm(dataloader, desc=f'Epoch {epoch+1}'):\n",
    "        article_ids = article_ids.to(device)\n",
    "        article_masks = article_masks.to(device)\n",
    "        summary_ids = summary_ids.to(device)\n",
    "        summary_masks = summary_masks.to(device)\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # Encoder forward\n",
    "        _, hidden = encoder(article_ids, article_masks)\n",
    "\n",
    "        # Decoder forward (teacher forcing)\n",
    "        decoder_input = summary_ids[:, :-1]\n",
    "        decoder_masks = summary_masks[:, :-1]\n",
    "        target = summary_ids[:, 1:]\n",
    "        \n",
    "        output, _ = decoder(decoder_input, hidden, decoder_masks)\n",
    "        output = output.reshape(-1, output.size(-1))\n",
    "        target = target.reshape(-1)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        batch_count += 1\n",
    "    \n",
    "    avg_loss = epoch_loss / batch_count\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea95189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference with BERT embeddings\n",
    "def summarize_article_bert(article_text):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Tokenize input article\n",
    "        inputs = bert_tokenizer(\n",
    "            article_text,\n",
    "            max_length=max_article_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        article_ids = inputs['input_ids'].to(device)\n",
    "        article_mask = inputs['attention_mask'].to(device)\n",
    "        \n",
    "        # Encode\n",
    "        _, hidden = encoder(article_ids, article_mask)\n",
    "        \n",
    "        # Decode\n",
    "        input_token = torch.tensor([[bert_tokenizer.cls_token_id]]).to(device)\n",
    "        summary_tokens = []\n",
    "        \n",
    "        for _ in range(max_summary_len):\n",
    "            # Create attention mask for single token\n",
    "            attention_mask = torch.ones_like(input_token).to(device)\n",
    "            \n",
    "            output, hidden = decoder(input_token, hidden, attention_mask)\n",
    "            token_id = output.argmax(-1)[:, -1].item()\n",
    "            \n",
    "            if token_id == bert_tokenizer.sep_token_id or token_id == bert_tokenizer.pad_token_id:\n",
    "                break\n",
    "                \n",
    "            summary_tokens.append(token_id)\n",
    "            input_token = torch.tensor([[token_id]]).to(device)\n",
    "        \n",
    "        # Decode tokens to text\n",
    "        summary = bert_tokenizer.decode(summary_tokens, skip_special_tokens=True)\n",
    "        return summary\n",
    "\n",
    "# Example usage\n",
    "new_article = \"The morning began with a soft drizzle that painted the streets in a shimmering glaze, each raindrop bouncing off the pavement before sliding into shallow puddles that reflected fragments of the gray sky. Along the narrow lane, small shops opened one after another, their metal shutters creaking upward to reveal the colors and smells of daily life—fresh bread from the bakery, earthy spices from the grocer, and the faint tang of ink and paper from the bookstore at the corner. People moved in a slow rhythm, some clutching umbrellas while others simply embraced the rain, their clothes damp but their expressions calm, as though they had grown used to the unpredictability of the weather. A street dog trotted along confidently, pausing now and then at doorsteps where familiar hands reached out with scraps of food, a quiet reminder of the kindness woven into ordinary days. Somewhere in the distance, a bell rang—perhaps from a nearby temple or school—its sound cutting through the misty air and marking the passage of another hour. Inside a dimly lit café, the chatter of early customers blended with the hiss of steaming milk and the sharp click of ceramic cups being placed on wooden tables. The air carried a comforting warmth, wrapping around anyone who stepped inside, offering a small refuge from the damp world beyond the glass windows. It was one of those mornings that felt suspended between movement and stillness, inviting both reflection and the gentle anticipation of what the rest of the day might hold.\"\n",
    "\n",
    "print(\"Generated Summary:\")\n",
    "print(summarize_article_bert(new_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb25afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained models\n",
    "torch.save(encoder.state_dict(), 'bert_encoder_model.pth')\n",
    "torch.save(decoder.state_dict(), 'bert_decoder_model.pth')\n",
    "print(\"Models saved successfully!\")\n",
    "\n",
    "# To load the models later:\n",
    "# encoder.load_state_dict(torch.load('bert_encoder_model.pth'))\n",
    "# decoder.load_state_dict(torch.load('bert_decoder_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f7d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
